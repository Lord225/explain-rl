# Explainable Vision Reinforcement Learning with PPO and Vision Transformers

This repository contains the implementation and results of a thesis project focused on enhancing the explainability of reinforcement learning (RL) agents using vision-based observations. 
The project investigates the use of Proximal Policy Optimization (PPO) combined with Vision Transformers (ViTs) and proposes novel methods for improving model interpretability.

 Our analysis reveals a significant improvement, with a 41% lower in mean squared error (MSE) loss between segmentation and embeddings correlation.  
 Furthermore, agent behavior interpretability is analyzed using tools such as decision trees. 
 Experimental results demonstrate that the proposed methods significantly enhance both the explainability of the models and the stability of the training process.
 
![segmentation gen](explain/segmentations_second-2.gif

![rewards](plots/reward-comp.png)

![explainer](plots/comp-explainer-loss.png)

![attention](explain/attention-20250418-212536-WhenFactBe_69_v4.2.gif)
